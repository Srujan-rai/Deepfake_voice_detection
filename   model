{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1LFyLh1IrqYUgKsxXQnmrBRBkWLdv3DZF",
      "authorship_tag": "ABX9TyMBIRey6+NGsLsp4J8g/5rx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srujan-rai/Deepfake_voice_detection/blob/main/%20%20model\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sp5xEAkucagw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/Deepfake/Deepfake - Voice Detection/KAGGLE/DATA'  # Path to the 'data' directory\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "for label in os.listdir(data_dir):\n",
        "    label_dir = os.path.join(data_dir, label)\n",
        "    for image_filename in os.listdir(label_dir):\n",
        "        image_paths.append(os.path.join(label_dir, image_filename))\n",
        "        labels.append(label)\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(image_paths, labels, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "image_height=640\n",
        "image_width=480\n",
        "\n",
        "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_height, image_width, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "train_datagen = datagen.flow_from_directory(data_dir,\n",
        "                                            target_size=(image_height, image_width),\n",
        "                                            batch_size=32,\n",
        "                                            class_mode='categorical',\n",
        "                                            subset='training')\n",
        "val_datagen = datagen.flow_from_directory(data_dir,\n",
        "                                          target_size=(image_height, image_width),\n",
        "                                          batch_size=32,\n",
        "                                          class_mode='categorical',\n",
        "                                          subset='validation')\n",
        "\n",
        "\n",
        "history = model.fit(train_datagen,\n",
        "                    validation_data=val_datagen,\n",
        "                    epochs=10,\n",
        "                    verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fHZ79LFkNeW",
        "outputId": "66c7155b-24e4-4368-fc3f-33b28df97e89"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 262 images belonging to 2 classes.\n",
            "Found 65 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 236s 25s/step - loss: 31.1046 - accuracy: 0.4924 - val_loss: 0.7370 - val_accuracy: 0.4615\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 193s 21s/step - loss: 0.7609 - accuracy: 0.5038 - val_loss: 0.6921 - val_accuracy: 0.5231\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 195s 23s/step - loss: 0.6855 - accuracy: 0.5458 - val_loss: 0.6763 - val_accuracy: 0.5692\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 195s 21s/step - loss: 0.6826 - accuracy: 0.5458 - val_loss: 0.6871 - val_accuracy: 0.5538\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 194s 21s/step - loss: 0.6942 - accuracy: 0.5038 - val_loss: 0.6684 - val_accuracy: 0.5538\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 183s 20s/step - loss: 0.6616 - accuracy: 0.6069 - val_loss: 0.6888 - val_accuracy: 0.5231\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 188s 20s/step - loss: 0.6938 - accuracy: 0.5267 - val_loss: 0.6564 - val_accuracy: 0.6462\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 192s 21s/step - loss: 0.6762 - accuracy: 0.5420 - val_loss: 0.6468 - val_accuracy: 0.5846\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 194s 21s/step - loss: 0.6827 - accuracy: 0.5496 - val_loss: 0.6528 - val_accuracy: 0.6462\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 193s 21s/step - loss: 0.6694 - accuracy: 0.6031 - val_loss: 0.6593 - val_accuracy: 0.6154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Deepfake/Deepfake - Voice Detection/KAGGLE/MODEL/deepfake.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "udJxe3cHnCQ7",
        "outputId": "a8788bff-ab5c-4374-aefa-5bfbc25f89c8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-22eda864a9aa>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Deepfake/Deepfake - Voice Detection/KAGGLE/MODEL/deepfake.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'save'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('deepfake_model.h5')"
      ],
      "metadata": {
        "id": "X3RDPxtiti5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "base_path='/content/drive/MyDrive/Deepfake/Deepfake - Voice Detection/KAGGLE'\n",
        "folder_name='MODEL'\n",
        "\n",
        "folder_path=os.path.join(base_path,folder_name)\n",
        "os.makedirs(folder_path,exist_ok=True)\n"
      ],
      "metadata": {
        "id": "fpb5f0e5u56J"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import os\n",
        "model='/content/drive/MyDrive/Deepfake/Deepfake - Voice Detection/KAGGLE/MODEL'\n",
        "model.save(os.path.join(model,\"deepfake_model.h5\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "SYt3UYn_vsLy",
        "outputId": "35b57078-a18e-4d8d-ab23-1942ed7bb6e9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c2c8b4641eaf>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Deepfake/Deepfake - Voice Detection/KAGGLE/MODEL'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"deepfake_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'save'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Load the model\n",
        "model = keras.models.load_model('/content/deepfake_model.h5')\n",
        "\n",
        "# Perform any operations or predictions with the loaded model\n",
        "\n",
        "# If you want to save the model again to the same or a different location:\n",
        "model.save('/content/drive/MyDrive/Deepfake/Deepfake - Voice Detection/KAGGLE/MODELnew_deepfake_model.h5')\n"
      ],
      "metadata": {
        "id": "92qE0Z3mwmFk",
        "outputId": "6788966d-5756-4f1a-9e68-261fc515038c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}